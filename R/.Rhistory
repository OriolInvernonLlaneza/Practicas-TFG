library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R/cartas")
ex  <- VCorpus(DirSource("cartas\\ejemplo"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
ex <- tm_map(ex , stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
sn <-
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
matrix <-DocumentTermMatrix(ex) #matriz
v <- sort(rowSums(matrix), decreasing=TRUE) #ordenarla por frecuencia
d <- data.frame(word = names(v), freq = v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
findFreqTerms(matrix, lowfreq = 4) #buscar términos más comunes en matriz
findAssocs(matrix, terms = "señor", corlimit = 0.3) #buscar términos que van juntos
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
ex  <- VCorpus(DirSource("cartas\\ejemplo"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
ex <- tm_map(ex , stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
sn <-
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
matrix <-DocumentTermMatrix(ex) #matriz
v <- sort(rowSums(matrix), decreasing=TRUE) #ordenarla por frecuencia
d <- data.frame(word = names(v), freq = v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
findFreqTerms(matrix, lowfreq = 4) #buscar términos más comunes en matriz
findAssocs(matrix, terms = "señor", corlimit = 0.3) #buscar términos que van juntos
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
View(ex)
View(matrix)
library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
ex  <- VCorpus(DirSource("cartas\\ejemplo"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
ex <- tm_map(ex , stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
sn <-
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
matrix <-DocumentTermMatrix(ex) #matriz
v <- sort(rowSums(matrix), decreasing=TRUE) #ordenarla por frecuencia
d <- data.frame(word = names(v), freq = v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
findFreqTerms(matrix, lowfreq = 4) #buscar términos más comunes en matriz
findAssocs(matrix, terms = "señor", corlimit = 0.3) #buscar términos que van juntos
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
ex  <- VCorpus(DirSource("cartas\\ejemplo"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
ex <- tm_map(ex , stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
sn <-
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
matrix <-DocumentTermMatrix(ex) #matriz
m <- as.matrix(matrix) #treat dtm as amtrix
v <- sort(rowSums(m), decreasing=TRUE) #ordenarla por frecuencia
d <- data.frame(word = names(v), freq = v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
findFreqTerms(matrix, lowfreq = 4) #buscar términos más comunes en matriz
findAssocs(matrix, terms = "señor", corlimit = 0.3) #buscar términos que van juntos
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
ex  <- VCorpus(DirSource("cartas\\ejemplo"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
ex <- tm_map(ex , stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
sn <-
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
matrix <-DocumentTermMatrix(ex) #matriz
m <- as.matrix(matrix) #treat dtm as amtrix
v <- sort(rowSums(m), decreasing=TRUE) #ordenarla por frecuencia
d <- data.frame(word = names(v), freq = v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
ex  <- VCorpus(DirSource("cartas\\ejemplo"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
ex <- tm_map(ex , stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
sn <-
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
matrix <-DocumentTermMatrix(ex) #matriz
m <- as.matrix(matrix) #treat dtm as amtrix
v <- sort(rowSums(m), decreasing=TRUE) #ordenarla por frecuencia
d <- data.frame(word = names(v), freq = v)
inspect(d)
library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
ex  <- VCorpus(DirSource("cartas\\ejemplo"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
ex <- tm_map(ex , stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
sn <-
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
matrix <-DocumentTermMatrix(ex) #matriz
m <- as.matrix(matrix) #treat dtm as amtrix
v <- sort(rowSums(m), decreasing=TRUE) #ordenarla por frecuencia
d <- data.frame(word = names(v), freq = v)
head(d, 10)
library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
ex  <- VCorpus(DirSource("cartas\\ejemplo"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
ex <- tm_map(ex , stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
matrix <-DocumentTermMatrix(ex) #matriz
m <- as.matrix(matrix) #treat dtm as amtrix
v <- sort(rowSums(m), decreasing=TRUE) #ordenarla por frecuencia
d <- data.frame(word = names(v), freq = v)
head(d, 10)
library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
ex  <- VCorpus(DirSource("cartas\\ejemplo", encoding = "UTF-8"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex  <- VCorpus(DirSource(directory = "cartas\\ejemplo", encoding = "UTF-8"), readerControl = list(language="es"))
summary(ex)  #check what went in
inspect(ex[[1]])
ex  <- VCorpus(DirSource(directory = "cartas\\ejemplo", encoding = "UTF-8"), readerControl = list(language="es"))
summary(ex)  #check what went in
inspect(ex[[1]])
inspect(ex[[2]])
ex  <- VCorpus(DirSource(directory = "cartas\\ejemplo", encoding = "UTF-8"), readerControl = list(language="es"))
summary(ex)  #check what went in
inspect(ex[[1]])
ex  <- VCorpus(DirSource(directory = "cartas\\ejemplo", encoding = "UTF-8"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
ex <- tm_map(ex , stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
inspect(ex)
inspect(ex[[1]])
matrix <-DocumentTermMatrix(ex) #matriz
m <- as.matrix(matrix) #treat dtm as amtrix
v <- sort(rowSums(m), decreasing=TRUE) #ordenarla por frecuencia
d <- data.frame(word = names(v), freq = v)
head(d, 10)
inspect(matrix)
library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
ex  <- VCorpus(DirSource(directory = "cartas\\ejemplo", encoding = "UTF-8"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
ex <- tm_map(ex , stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
inspect(ex[[1]])
wordcloud(jeopCorpus, max.words = 100, random.order = FALSE)
wordcloud(ex, max.words = 100, random.order = FALSE)
library("NLP")
library("tm") #load text mining library
library("SnowballC")
library("RColorBrewer")
library("wordcloud")
#setwd("D:/Users/Oriol/Documents/practicas/proyecto/R")
ex  <- VCorpus(DirSource(directory = "cartas\\ejemplo", encoding = "UTF-8"), readerControl = list(language="es"))
summary(ex)  #check what went in
ex <- tm_map(ex, removeNumbers) #números
ex <- tm_map(ex, removePunctuation) #puntuación
#ex <- tm_map(ex, stripWhitespace) #espacios en blanco extras
ex <- tm_map(ex, stemDocument, language = "spanish") #Sacar raíces
ex <- tm_map(ex, content_transformer(tolower)) #a minus
ex <- tm_map(ex, removeWords, stopwords("spanish")) #Borrar palabras vacías.
ex <- tm_map(ex, removeWords, c("ejemplo1", "ejemplo2")) #Borrar palabras custom
inspect(ex[[1]])
wordcloud(ex, max.words = 100, random.order = FALSE)
wordcloud(ex, max.words = 200, random.order = FALSE, scale=c(4,.5))
wordcloud(ex, max.words = 200, random.order = FALSE)
wordcloud(ex, max.words = 200, random.order = FALSE,colorPalette="Dark2")
wordcloud(ex, max.words = 200, random.order = FALSE, colorPalette="Dark2")
warning()
warnings()
